## Learn-Fine-tune-LLM

This repository contains resources, code, and experiments for fine-tuning large language models (LLMs). It demonstrates how to:

1. Prepare datasets for supervised fine-tuning (SFT)

2. Apply LoRA (Low-Rank Adaptation) for efficient parameter tuning

3. Use Unsloth, Transformers, and TRL to fine-tune LLaMA models

4. Run inference and deploy fine-tuned models

5. Push trained adapters/models to Hugging Face Hub

The repo is designed for learners, researchers, and developers who want to understand the end-to-end process of customizing LLMs for domain-specific tasks
